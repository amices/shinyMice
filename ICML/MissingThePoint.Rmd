---
title: "Missing The Point:"
subtitle: "Non-Convergence in Iterative Imputation Algorithms"
author: "Hanne I. Oberman, Stef van Buuren, Gerko Vink"
institute: "ICML ARTEMISS workshop 2020"
date: "17-07-2020" #(updated: `r Sys.Date()`)"
output:
  xaringan::moon_reader:
    css: [default, default-fonts]
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---


```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
```


# Algorithmic Convergence

With iterative imputation, the validity of inferences relies on algorithmic convergence. Signs of non-convergence (i.e., non-mixing, trending) are typically identified through visual inspection.

<br>

<!-- .footer[Missing The Point | Oberman, van Buuren, Vink | 2020 | github.com/hanneoberman/MissingThePoint] -->


```{r non-conv, echo=FALSE, fig.width=10, fig.height = 5.2, message=FALSE, warning=FALSE}
# set-up env
library(dplyr)
library(ggplot2)
library(plotly)
library(mice)
#load("example_diagnostics.Rdata")
load("../traceplotdata.Rdata")

# define colorblind friendly colors
paint5 <- c('#228833', '#66CCEE', '#CCBB44','#EE6677', '#AA3377')
# paint2 <- c('#66CCEE', '#EE6677')
# 
# # plot chain
# trace <- ggplot(diagnostics) +
#   geom_point(aes(x = iteration, y = `Chain 1`, color = patho),
#              size = .5,
#              na.rm = TRUE) +
#   geom_point(aes(x = iteration, y = `Chain 2`, color = patho),
#              size = .5,
#              na.rm = TRUE) +
#   geom_point(aes(x = iteration, y = `Chain 3`, color = patho),
#              size = .5,
#              na.rm = TRUE) +
#   geom_point(aes(x = iteration, y = `Chain 4`, color = patho),
#              size = .5,
#              na.rm = TRUE) +
#   geom_point(aes(x = iteration, y = `Chain 5`, color = patho),
#              size = .5,
#              na.rm = TRUE) +
#   geom_line(aes(x = iteration, y = `Chain 2`, color = patho), size = .5, na.rm = TRUE) +
#   geom_line(aes(x = iteration, y = `Chain 3`, color = patho), size = .5, na.rm = TRUE) +
#   geom_line(aes(x = iteration, y = `Chain 1`, color = patho), size = .5, na.rm = TRUE) +
#   geom_line(aes(x = iteration, y = `Chain 4`, color = patho), size = .5, na.rm = TRUE) +
#   geom_line(aes(x = iteration, y = `Chain 5`, color = patho), size = .5, na.rm = TRUE) +
#   scale_colour_manual(values=paint2) +
#   scale_x_continuous(breaks = 1:10) +
#   xlab("Iteration") +
#   ylab("Chain mean") + #bquote(theta)) +
#   labs(color = "") + 
#   theme_classic() +
#   theme(legend.position = "bottom")
  
#ggplotly(trace)

# alternatively, use the actual data
# run 1.Execute.R until imputing anything, than run RunSimulationOnce.R until after amputing the data
# with the 'amps' object
set.seed(12)
d75 <- amps[[4]] %>% mice(maxit=10, printFlag = FALSE)
#plot(d75)
p <- gg.mids(d75, x="Y")[[1]] 
p <- p + 
  scale_color_manual(values = paint5) + 
  scale_x_continuous(breaks = 1:10) + 
  labs(
    #title = "Traceplot", 
    x = "Iteration",
    y = "Chain mean", 
    colour = "Imp.")

ggplotly(p)

```
---

# Simulation Study

When imputing an incomplete multivariate normal set ( $n_{\rm obs}=1000$, $n_{\rm sim} = 1000$), we obtain valid regression estimates after 5 to 10 iterations. <!-- Multivariate normal set ( $n = 1000$ ), 'amputed' with a varying proportion of incomplete cases, and 'imputed' with a varying number of iterations. Depicted are the bias and coverage rate of an estimated regression coefficient ( $n_{\rm sim} = 1000$ ). -->

<br>

```{r results, echo=FALSE, fig.width=9.8, message=FALSE, warning=FALSE}
load("complete.Rdata") 
#library(patchwork) 

# pre-processing
results <- results %>% filter(t<51) %>% mutate(bias.est.X1 = bias.est.X1/.0206) %>% mutate(crit = qnorm((1 + .95) / 2) / sqrt(t), thresh1.01 = 1.01, thresh1.1 = 1.1, thresh1.2 = 1.2)
results$crit[results$crit>1] <- NA

# create plots
est_bias <- results %>% ggplot(aes(x = t, y = bias.est.X1, color = as.factor(p*100))) +
  geom_hline(yintercept = 0,
             color = "grey",
             lwd = 1) +
  geom_point(size = .5, na.rm = TRUE) +
  geom_line(size = .5, na.rm = TRUE) +
  scale_colour_manual(values=paint5) +
  labs(
    #title = "Average bias in regression estimate", 
    #subtitle = "Multivariate normal data (n = 1000, nsim = 1000)", 
    x = "Number of iterations", 
    y = "Bias (%)", 
    colour = "Miss. (%)") +
  theme_classic() +
  theme(legend.position = "top")

est_Rh <- results %>% ggplot(aes(x = t, y = r.hat.max.beta, color = as.factor(p*100))) +
  geom_hline(yintercept = 1,
             color = "grey",
             lwd = 
               1) +
  geom_point(size = .5, na.rm = TRUE) +
  geom_line(size = .5, na.rm = TRUE) +
  geom_line(aes(x=t, y=thresh1.2), color = "grey", linetype = "dashed", size = .25, na.rm = TRUE) +
  geom_line(aes(x=t, y=thresh1.1), color = "grey", linetype = "dashed", size = .25, na.rm = TRUE) +
  geom_line(aes(x=t, y=thresh1.01), color = "grey", linetype = "dashed", size = .25, na.rm = TRUE) +
  scale_colour_manual(values=paint5) +
  scale_y_continuous(limits = c(1,1.53), breaks = c(1,1.1,1.2,1.3,1.4,1.5)) +
  labs(x = "Number of iterations", 
       y = "Å˜", #r'$\\widehat{R}$'
       colour = "Miss. (%)") +
  theme_classic() +
  theme(legend.position = "bottom")

est_AC <- results %>% ggplot(aes(x = t, y = ac.max.beta, color = as.factor(p*100))) +
  geom_hline(yintercept = 0,
             color = "grey",
             lwd = 1) +
  geom_line(aes(x = t, y = crit), color = "grey", linetype = "dashed", size = .25, na.rm = TRUE) + 
  geom_point(size = .5, na.rm = TRUE) +
  geom_line(size = .5, na.rm = TRUE) +
  scale_colour_manual(values=paint5) +
  labs(x = "Number of iterations",
       y = "Auto-correlation",
       colour = "Miss. (%)") +
  theme_classic() +
  theme(legend.position = "bottom")

est_cov <- results %>% ggplot(aes(x = t, y = cov.est.X1*100, color = as.factor(p*100))) +
  geom_hline(yintercept = 95,
             color = "grey",
             lwd = 1) +
  geom_point(size = .5, na.rm = TRUE) +
  geom_line(size = .5, na.rm = TRUE) +
  scale_colour_manual(values=paint5) +
  xlab("Number of iterations") +
  ylab("Coverage rate (%)") +
  labs(colour = "Miss. (%)") +
  theme_classic() +
  theme(legend.position = "") 

# plot estimates, save 6.75x4.5in or 5.5
# est_bias + est_cov + est_AC + est_Rh + plot_annotation(tag_levels = "A", tag_suffix = ".") + plot_layout(ncol = 2, guides = "collect")

```

.pull-left[
```{r echo=FALSE, fig.width=5.1, fig.height=5.4, message=FALSE, warning=FALSE}
ggplotly(est_bias)
```
]

.pull-right[
```{r echo=FALSE, fig.width=5.1, fig.height=5.4, message=FALSE, warning=FALSE}
ggplotly(est_cov)
```
]

---

# Simulation Study (2)

Whereas non-convergence diagnostics $\widehat{R}$ and auto-correlation identify signs of non-convergence up-to 30 to 50 iterations.

<br>

.pull-left[
```{r echo=FALSE, fig.width=5.1, fig.height=5.4, message=FALSE, warning=FALSE}
ggplotly(est_Rh)
```
]

.pull-right[
```{r echo=FALSE, fig.width=5.1, fig.height=5.4, message=FALSE, warning=FALSE}
ggplotly(est_AC)
```
]

---
# Take-away

We conclude that&mdash;in the cases considered&mdash;it never hurts to iterate longer, but such calculations hardly bring added value.

<br> 

Read more on [github.com/hanneoberman/MissingThePoint](https://github.com/hanneoberman/MissingThePoint). Or follow my updates through Twitter [@hioberman](https://twitter.com/hioberman).

.pull-left[
<br> <br> <br>
<br> <br> <br>
<br> <br> <br>
Upcoming...
]

.pull-right[
<img src="https://raw.githubusercontent.com/gerkovink/shinyMice/2dae400d9d23ede7bec031c1501acdc681eab13c/ThesisProposal/Figures/logo.png" width="420">
]

<!-- .footnote[Slides created via the R package [**xaringan**](https://github.com/yihui/xaringan).] -->

